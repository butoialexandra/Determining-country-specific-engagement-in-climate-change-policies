{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Data_Collection:PDF_Scraping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPe/06t1rUB0xZtey6JCMcR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/butoialexandra/Determining-country-specific-engagement-in-climate-change-policies/blob/main/2_Data_Collection_PDF_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46tWLa2GhSMR"
      },
      "source": [
        "Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fDxWMfUg3qS",
        "outputId": "b8a4ffbd-723c-4eaf-a194-0bbb2ba2476d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVkiO5SApl0p",
        "outputId": "d6c94695-cd7e-4b9c-d9ed-58caf209bba4"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muW0v9S6n9Gn"
      },
      "source": [
        "Install some extra libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljcFh9qyhXpF"
      },
      "source": [
        "!pip install pyMuPDF\n",
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXuJN9U0oNki"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqg46PNuoBnt"
      },
      "source": [
        "import fitz\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdAziOfbokOY"
      },
      "source": [
        "Parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1oSDqd6yKbe"
      },
      "source": [
        "class PDFParser():\n",
        "\n",
        "    def __init__(self, dir):\n",
        "        self.dir = dir\n",
        "        # all English documents from the input dir\n",
        "        self.docs = [f for f in glob.glob(\"{}/*.pdf\".format(self.dir)) if f[f.rfind('_')+1:-4] == \"English\"]\n",
        "\n",
        "    def save_text(self, doc):\n",
        "        try:\n",
        "            document = fitz.open(doc)\n",
        "            no_pages = document.pageCount\n",
        "            doc_texts = self.process_document(document, no_pages)\n",
        "            # save each paragraph\n",
        "            for i, text in enumerate(doc_texts):\n",
        "                file_name = 'txts' + doc[doc.rfind('/'):-4] + '_Paragraph{}'.format(i) + '.txt'\n",
        "                with open(file_name, 'w') as f:\n",
        "                    f.write(text)\n",
        "        except:\n",
        "            print(doc)\n",
        "\n",
        "\n",
        "    def save_all(self):\n",
        "        for doc in tqdm(self.docs):\n",
        "            self.save_text(doc)\n",
        "\n",
        "    def process_text(self, text):\n",
        "        text = text.strip() # remove trailing spaces\n",
        "        text = re.sub(r'<image:(.*)>', '', text)  # remove images\n",
        "        text = re.sub(r'\\n', '', text) # remove new line\n",
        "        text = re.sub(' +', ' ', text).strip() # remove multiple spaces\n",
        "        text = re.sub(r'[^a-zA-Z0-9 ,.;()\\'\"]', '', text) # remove anything that is not alphanumeric or punctuation\n",
        "\n",
        "        return text\n",
        "\n",
        "    def process_page(self, document, page_no):\n",
        "        page = document.loadPage(page_no)\n",
        "        page_text = page.getText(\"blocks\")\n",
        "        texts = [x for _, _, _, _, x, _, _ in page_text]\n",
        "        texts = [self.process_text(text) for text in texts]\n",
        "        texts = [text for text in texts if text != '' and len(text) >= 50]\n",
        "\n",
        "        return texts\n",
        "\n",
        "    def process_document(self, document, no_pages):\n",
        "        texts = []\n",
        "        for i in range(no_pages):\n",
        "            texts.extend(self.process_page(document, i))\n",
        "\n",
        "        return texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWv29pbo6A8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06f67c2-b5a3-424b-c15f-e0c95eb0c54a"
      },
      "source": [
        "pdf_parser = PDFParser(\"national-climate-plans/pdfs\")\n",
        "pdf_parser.save_all()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 56/148 [03:03<06:13,  4.06s/it]mupdf: cannot recognize version marker\n",
            "mupdf: no objects found\n",
            " 39%|███▊      | 57/148 [03:03<04:31,  2.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "national-climate-plans/pdfs/ISR_Israel_First_NDC_English.pdf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 129/148 [07:03<00:31,  1.65s/it]mupdf: missing font descriptor\n",
            "mupdf: missing font descriptor\n",
            "100%|██████████| 148/148 [08:07<00:00,  3.30s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLKP0FvqtDW7",
        "outputId": "43a72bab-e09e-4879-88db-e7280035b545"
      },
      "source": [
        "path, dirs, files = next(os.walk(\"./txts\"))\n",
        "file_count = len(files)\n",
        "print(\"{} files\".format(file_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28738 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMxtPQo6Neyx"
      },
      "source": [
        "Additionally you can a generate csv with the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L503VoGMNdd7"
      },
      "source": [
        "docs = [f for f in glob.glob(\"./txts/*.txt\")]\n",
        "texts = []\n",
        "for doc in tqdm(docs):\n",
        "    with open(doc, 'r') as f:\n",
        "        text = f.read()\n",
        "    texts.append(text)\n",
        "# data dictionary\n",
        "data = {\n",
        "    'Document': docs,\n",
        "    'NDC': texts\n",
        "}\n",
        "# write dataframe to csv\n",
        "df = pd.DataFrame.from_dict(data)\n",
        "df.to_csv(\"data.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}